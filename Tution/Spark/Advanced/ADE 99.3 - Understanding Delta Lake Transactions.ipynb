{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Understanding Delta Lake Transactions\n",
    "\n",
    "To provide atomic, durable transactions in the Lakehouse, Delta Lake utilizes transaction logs stored alongside data files. This notebook dives into the transaction logs to demonstrate what information is recorded and explore how the current version of the table is materialized.\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this lessons, student will be able to:\n",
    "- Describe how Delta Lake tracks and manages transactions\n",
    "- Define the atomicity and durability guarantees of Delta Lake\n",
    "- Map transactional metadata back to table operations"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "98f9a199-054c-4bda-845e-3a085f44f1d7",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "Run the following script to setup necessary variables and clear out past runs of this notebook."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "bf4d3195-0034-4629-b44a-a24b0ccb8559",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%run ../Includes/Classroom-Setup-1.3"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "d3d871a2-ae3a-492a-b709-fc1585e82c75",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Atomic, Durable Transactions in the Lakehouse\n",
    "\n",
    "Briefly, Delta Lake transactions can be described as the following:\n",
    "- All write operations commit data changes as Parquet files\n",
    "- Transactions commit when JSON log files are written\n",
    "- Logs are stored in a nested directory\n",
    "- Both data and transaction logs inherit the durability guarantees of the file system\n",
    "\n",
    "The cloud-based object storage used by Databricks provides the following advantages and guarantees:\n",
    "- Infinitely scalable\n",
    "- Affordable\n",
    "- Availability:  > 99.9%\n",
    "- Durability: > 99.999999999%\n",
    "\n",
    "Note that the Databricks platform has SLAs separate from cloud vendor infrastructure, and the guarantees of each cloud vendor differ slightly."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "a842458e-682a-459e-ba79-3fb118f8f5dc",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create a Table and Insert Records\n",
    "\n",
    "The cell below contains 4 Delta Lake operations."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "d7c94255-a937-4913-93ff-407717d14b6c",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%sql\n",
    "\n",
    "CREATE TABLE bronze \n",
    "(id INT, name STRING, value DOUBLE); \n",
    "\n",
    "INSERT INTO bronze VALUES (1, \"Yve\", 1.0);\n",
    "INSERT INTO bronze VALUES (2, \"Omar\", 2.5);\n",
    "INSERT INTO bronze VALUES (3, \"Elia\", 3.3);"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "1796076c-61b9-4e1b-9af3-c9880caf0ccc",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "As expected, the table has three rows."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "8133dbe1-299d-4afd-be9b-f223d66a762a",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%sql\n",
    "SELECT * FROM bronze"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "333fd14f-73d6-437c-b155-2d62e643bffe",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reviewing the history allows us to see how operations and versions are linked."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "e1e6d38d-907a-42e1-a9ca-1246414c3f45",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%sql\n",
    "DESCRIBE HISTORY bronze"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "15a35a72-d1cd-48cf-b94f-2d9d9c2cb813",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "The transaction log directory is nested under the table directory and contains a log file for each transaction (alongside checksum files and other files used to manage consistency with cloud object storage)."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "e43fc0a0-5761-48b2-95bb-f8231c5230d6",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "files = dbutils.fs.ls(f\"{DA.paths.user_db}/bronze/_delta_log\")\n",
    "display(files)"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "cfa1a52b-1598-4a03-ba3b-6df77c80edc7",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "The table was created without any data present, so the initial version only contains metadata about the table schema and the user, environment, and time of the transaction.\n",
    "\n",
    "Note that the transaction log is a simple JSON file, which can be reviewed directly from the file or read with Spark."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "9c1823a4-cf26-4578-b140-f163d5656419",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "display(spark.read.json(f\"{DA.paths.user_db}/bronze/_delta_log/00000000000000000000.json\"))"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "bfd26e0b-c857-42b5-8302-a974924bd9d3",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "The cell below leverages a Databricks setting to automatically return the Delta transaction log for the most recent commit version."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "7aadc7c4-e5b2-4814-ab21-4e6b0737604a",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def display_delta_log(table, version=None):\n",
    "    if not version:\n",
    "        version = spark.conf.get(\"spark.databricks.delta.lastCommitVersionInSession\")\n",
    "    version_str = str(int(version)).zfill(20)\n",
    "    file = f\"{DA.paths.user_db}/{table}/_delta_log/{version_str}.json\"\n",
    "    print(\"Showing: \"+file)\n",
    "    display(spark.read.json(file))"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "99447051-2b41-487f-8471-90bbfd27cecb",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we'll see that a simple insert transaction results in new files being tracked in the **`add`** column alongside **`commitInfo`**."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "e99a2d1a-8418-4ad5-b01f-a943e7b7828f",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "display_delta_log(\"bronze\")"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "e64d6c14-2319-4c16-867e-b4a09fa17652",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Appending Data\n",
    "Note that when appending data, multiple data files may be written as part of a single transaction."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "a8e1475c-7e4d-4b54-99a1-33905e1f2bf2",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%sql\n",
    "INSERT INTO bronze\n",
    "VALUES (4, \"Ted\", 4.7),\n",
    "       (5, \"Tiffany\", 5.5),\n",
    "       (6, \"Vini\", 6.3)"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "2fce8958-4441-439a-bff0-efde458aa94e",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "The **`add`** column below contains paths and stats for each of the files added to the table."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "3b8c19f1-f8d3-4542-a396-f817675ea4a8",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "display_delta_log(\"bronze\")"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "756d140c-951f-4d25-aa33-14883116706a",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Most append operations will insert many records into a single file."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "8a528643-4931-4d70-8fd1-12fba30554b6",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%sql\n",
    "INSERT INTO bronze SELECT * FROM new_records"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "f7e325e5-b947-4243-ab12-b096f0dc6cf2",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "As expected, multiple records appear in a single data file under the **`add`** column."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "1ae51253-3542-4a69-8baf-7dd55381e3e1",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "display_delta_log(\"bronze\")"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "c11e9954-805e-40ea-9f28-5078672a7472",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deleting Data\n",
    "Deleting a single record from a file with multiple records will actually result in a file being added."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "87aede17-125b-48b0-9eea-cd2d7cad8e22",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%sql \n",
    "DELETE FROM bronze WHERE name = \"Viktor\""
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "73c35095-4df3-4307-84e1-0232798bec8d",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "The file added contains the other records that were in the same data file as the record deleted in the transaction. \n",
    "\n",
    "In this specific case, the **`remove`** column indicates that the previous file with 3 records is no longer valid; the **`add`** column points to a new file containing only 2 records.\n",
    "\n",
    "This is the expected behavior, as Delta Lake does not modify data files in place."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "663639b5-8ec2-4ebe-af8a-c3426e54254a",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "display_delta_log(\"bronze\")"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "bb3cde1c-294a-48f3-8369-82430b58bfc4",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Updating Data\n",
    "Anytime a record in an existing file is modified, a new file will be added, and the old file will be indicated in the **`remove`** column, as in the update below."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "4718cd8b-f85e-4a7e-96b4-3b1228e656dc",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%sql\n",
    "UPDATE bronze SET name = \"Vincent\" WHERE id = 6"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "67e6952d-d470-46a9-a68e-53f21d5e60e2",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, both the file removed and the file rewritten contain only the modified record. In production environments, you are unlikely to see a data file containing a single record."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "62d66eb8-2f93-474f-80fd-9d921deb033f",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "display_delta_log(\"bronze\")"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "e25ca991-266b-4d6e-9ede-97a833bcbbd8",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Combining Transactions with Merge\n",
    "The Delta Lake **`MERGE`** syntax allows updates, deletes, and inserts to occur in a single transaction."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "668d5073-f3b5-4b22-bccf-27794fa7158c",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%sql\n",
    "MERGE INTO bronze b\n",
    "USING updates u\n",
    "ON b.id=u.id\n",
    "WHEN MATCHED AND u.type = \"update\"\n",
    "  THEN UPDATE SET *\n",
    "WHEN MATCHED AND u.type = \"delete\"\n",
    "  THEN DELETE\n",
    "WHEN NOT MATCHED AND u.type = \"insert\"\n",
    "  THEN INSERT *"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "37b44f96-b178-47ee-9d3e-24330f80c6ba",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looking at the table history, note how **`MERGE`** operations differ from **`DELETE`**, **`UPDATE`**, or **`INSERT`** transactions."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "730829e7-c8cc-44a4-9262-ca333b1b6f81",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%sql\n",
    "DESCRIBE HISTORY bronze"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "2fb12cde-0630-4cf1-8d98-a0101fce727c",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "The **`operationMetrics`** and **`operationParameters`** within the **`commitInfo`** describe the source data, the parameters for the query, and all the results of the transaction.\n",
    "\n",
    "Use the query below to find:\n",
    "- How many rows were in the **`updates`** table\n",
    "- How many records were inserted\n",
    "- How many records were deleted\n",
    "- How many records were updated\n",
    "- The total number of files removed\n",
    "- The total number of files added"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "9eaa2681-4707-4c1f-8d8e-a4c2f8b40f2f",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "display_delta_log(\"bronze\")"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "cddc8356-95fd-42dc-9938-b6b94deb2d3c",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Table Utility Functions\n",
    "Delta Lake table utility functions modify the metadata of a table without changing underlying data."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "88320274-cdb5-4d1a-b9cc-a6fb65fe01f5",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%sql\n",
    "ALTER TABLE bronze\n",
    "ALTER COLUMN name\n",
    "COMMENT \"User first name\""
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "a53447fd-02e9-4c5a-ba75-e75edf4eefff",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Files will not be marked as added or removed, as only the metadata has been updated."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "f46c2b46-5ee8-45bc-b76f-ec81a6aa9ed9",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "display_delta_log(\"bronze\")"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "09825a32-7528-4068-a221-2903b1a56e5c",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "## File Compaction\n",
    "Running **`OPTIMIZE`** on a table will compact small files toward the target file size."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "b0687483-3118-4573-815b-4b6a0d0ad6d6",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%sql\n",
    "OPTIMIZE bronze"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "536c938b-abe6-48d5-baf7-8d6d5ab69057",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "During file compaction, many files should be marked as removed, while a smaller number of files will be marked as added.\n",
    "\n",
    "No data or files are deleted during this operation; as always, adding files to the **`remove`** column means they will not be used when querying the current version of the table, but does not permanently delete them from the underlying storage."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "953ba41d-36c8-4a53-acf9-8c0a3625b939",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "display_delta_log(\"bronze\")"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "5d75dd7c-855c-460e-b16a-fe0bef4081df",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transaction Log Checkpoints\n",
    "Databricks will automatically create Parquet checkpoint files at fixed intervals to accelerate the resolution of the current table state.\n",
    "\n",
    "Version 10 of the table should have both a **`.json`** and a **`.checkpoint.parquet`** file associated with it."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "80b76c35-f2dc-4ed8-9a5d-3a084cc568e2",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "files = dbutils.fs.ls(f\"{DA.paths.user_db}/bronze/_delta_log\")\n",
    "display(files)"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "150f013a-3f43-4e6f-93bd-2d0a8fb863b2",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rather than only showing the operations of the most recent transaction, this checkpoint file condenses all of the **`add`** and **`remove`** instructions and valid **`metaData`** into a single file.\n",
    "\n",
    "This means that rather than loading many JSON files and comparing files listed in the **`add`** and **`remove`** columns to find those data files that currently represent the valid table version, a single file can be loaded that fully describes the table state.\n",
    "\n",
    "Transactions after a checkpoint leverage this starting point, resolved new info from JSON files with the instructions from this Parquet snapshot."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "12e3077a-8b72-45e0-bae0-76f510cf7f7a",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "display(spark.read.parquet(f\"{DA.paths.user_db}/bronze/_delta_log/00000000000000000010.checkpoint.parquet\"))"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "9c4d9a73-5ada-4fe8-9e8c-8b56c13b0f2f",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that all of the data files in both the **`add`** and **`remove`** columns are still present in the table directory."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "ffc5e250-8f35-4839-8eeb-281441decd35",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "files = dbutils.fs.ls(f\"{DA.paths.user_db}/bronze\")\n",
    "display(files)"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "3d51da6f-c742-4537-babf-3a2806475726",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cleaning Up Stale Data Files\n",
    "Executing **`VACUUM`** performs garbage cleanup on this directory. By default, a retention threshold of 7 days will be enforced; here it is overridden to demonstrate permanent removal of data. Manually setting **`spark.databricks.delta.vacuum.logging.enabled`** to **`True`** ensures that this operation is also recorded in the transaction log. \n",
    "\n",
    "**NOTE**: Vacuuming a production table with a short retention can lead to data corruption and/or failure of long-running queries."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "e8e48abf-b611-4d54-b99a-a855c273dfc2",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "spark.conf.set(\"spark.databricks.delta.vacuum.logging.enabled\", True)\n",
    "spark.conf.set(\"spark.databricks.delta.retentionDurationCheck.enabled\", False)\n",
    "spark.sql(\"VACUUM bronze RETAIN 0 HOURS\")\n",
    "spark.conf.set(\"spark.databricks.delta.retentionDurationCheck.enabled\", True)"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "18c4cc91-6842-4413-b7f9-4d1d5d6dd7fb",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "As expected, a single file remains."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "bd9c8196-cbc4-4615-8b60-8ff802ce9f0b",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "files = dbutils.fs.ls(f\"{DA.paths.user_db}/bronze\")\n",
    "display(files)"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "6c5333bf-0ed0-4e4f-9873-952f78105f53",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that both the start and end of the **`VACUUM`** operation are recorded in the history."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "827a5ed3-05bf-44b2-ae22-9ca80cd5333f",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%sql\n",
    "DESCRIBE HISTORY bronze"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "9a27e501-e1bb-4640-a940-a2f78081af93",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "The **`VACUUM START`** version will record the number of files to be deleted, but does not contain a list of file names.\n",
    "\n",
    "Once deleted, previous versions of the table relying on these files are no longer accessible."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "3aad2498-a8e8-4908-8088-ec2579dd55e8",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "display_delta_log(\"bronze\", 11)"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "3644a78e-1b3f-4e24-bf98-e2f454484ad6",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Additional reading is available in this <a href=\"https://databricks.com/blog/2019/08/21/diving-into-delta-lake-unpacking-the-transaction-log.html\" target=\"_blank\">blog post</a>."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "9558cd17-2958-4bf3-a7a9-b5a4fe7287d8",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run the following cell to delete the tables and files associated with this lesson."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "94194b18-b74d-4010-8608-4ff57702d4c8",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "DA.cleanup()"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "6d386b5d-5860-4a3c-9edb-ca543f6b3949",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "notebookName": "ADE 99.3 - Understanding Delta Lake Transactions",
   "dashboards": [],
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "language": "python",
   "widgets": {},
   "notebookOrigID": 4185566132530233
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}