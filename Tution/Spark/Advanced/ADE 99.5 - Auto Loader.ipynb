{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Ingest Data with Auto Loader\n",
    "\n",
    "Databricks Auto Loader is the recommended method for streaming raw data from cloud object storage. Auto Loader provides efficient, incremental, idempotent processing of data files from cloud object storage locations. Several enhancements to this ingestion method make it greatly preferred to directly streaming from the file source using open source Structured Streaming APIs.\n",
    "\n",
    "For small datasets, the default **directory listing** execution mode will provide provide exceptional performance and cost savings. As the size of your data scales, the preferred execution method is **file notification**, which requires configuring a connection to your storage queue service and event notification, which will allow Databricks to idempotently track and process all files as they arrive in your storage account.\n",
    "\n",
    "In this notebook, we'll go through the basic configuration to ingest the log files for device MAC addresses from partner gyms.\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/ade/ADE_arch_gym_logs.png\" width=\"60%\" />\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this lesson, students will be able to:\n",
    "- Use Auto Loader to incrementally, idempotently load data from object storage to Delta Tables\n",
    "- Locate operation metrics using the **`DESCRIBE HISTORY`** command"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "d8f1e6a8-af02-4bbe-918b-07823be1bcf2",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## File Detection Modes\n",
    "\n",
    "![](https://files.training.databricks.com/images/autoloader-detection-modes.png)\n",
    "\n",
    "Auto Loader can be configured with two different file detection modes. While directory listing mode is the default and works well for small datasets and testing, file notification mode is preferred for large scale production applications.\n",
    "\n",
    "| **Directory Listing Mode** | **File Notification Mode** |\n",
    "| --- | --- |\n",
    "| Default mode | Requires some security permissions to other cloud services |\n",
    "| Easily stream files from object storage without configuration | Uses cloud storage queue service and event notifications to track files |\n",
    "| Creates file queue through parallel listing of input directory | Configurations handled automatically by Databricks |\n",
    "| Good for smaller source directories | Scales well as data grows |\n",
    "\n",
    "**NOTE**: Only directory listing mode will be shown in this notebook."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "9e64794a-4bd3-4249-9c72-e485bb5cc99b",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Schema Inference and Evolution\n",
    "Auto Loader has advanced support for working with data sources with unknown or changing schemas, including the ability to:\n",
    "* Identify schema on stream initialization\n",
    "* Auto-detect changes and evolve schema to capture new fields\n",
    "* Add type hints for enforcement when schema is known\n",
    "* Rescue data that does not meet expectations\n",
    "\n",
    "Full documentation of this functionality is available <a href=\"https://docs.databricks.com/spark/latest/structured-streaming/auto-loader-schema.html\" target=\"_blank\">here</a>."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "d519133a-1b29-4471-9cc5-a5a3e698eb4b",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "\n",
    "The notebook below defines a function to allow us to manually trigger new data landing in our source container. \n",
    "\n",
    "This will allow us to see Auto Loader in action."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "adf3e7d2-2b22-4593-ac9d-98e6d4b473ee",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%run ../Includes/Classroom-Setup-1.5"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "4904ebef-4ef5-4905-a130-ef7e56ad79a0",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our source directory contains a number of JSON files representing about a week of data."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "38fabe2d-26dc-4308-8be2-6053886bf501",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "files = dbutils.fs.ls(DA.paths.gym_mac_logs_json)\n",
    "display(files)"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "b2b7575d-98c1-4e7b-81b0-97e4a740d467",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using CloudFiles\n",
    "\n",
    "Configuring Auto Loader requires using the **`cloudFiles`** format. \n",
    "\n",
    "The syntax for this format differs only slightly from a standard streaming read.\n",
    "\n",
    "To configure we need to:\n",
    "1. Specify the format as **`cloudFiles`**\n",
    "2. Specify the file format via **`cloudFiles.format`** as **`json`**\n",
    "3. Provide the location that Auto Loader will store the inferred schema via **`cloudFiles.schemaLocation`**\n",
    "4. Optionally configure Auto Loader to use cloud notifications via **`cloudFiles.useNotifications`**<br/>\n",
    "as opposed to listing the target directory. \n",
    "\n",
    "**Note:** The cloud-notifications feature does require additonal cloud configuration.\n",
    "\n",
    "See the <a href=\"https://docs.databricks.com/spark/latest/structured-streaming/auto-loader.html#configuration\" target=\"_blank\">Auto-Loader documentation</a> for more information."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "3faf4705-677d-469b-a50a-828c71e1144d",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def load_gym_logs():\n",
    "    query = (spark.readStream\n",
    "                  .format(\"cloudFiles\")\n",
    "                  .option(\"cloudFiles.format\", \"json\")\n",
    "                  .option(\"cloudFiles.schemaLocation\", f\"{DA.paths.checkpoints}/gym_mac_logs_schema\")\n",
    "                  # .option(\"cloudFiles.useNotifications\",\"true\") # Set this option for file notification mode\n",
    "                  .load(DA.paths.gym_mac_logs_json)\n",
    "                  .writeStream\n",
    "                  .format(\"delta\")\n",
    "                  .option(\"checkpointLocation\", f\"{DA.paths.checkpoints}/gym_mac_logs\")\n",
    "                  .trigger(availableNow=True)\n",
    "                  .table(\"gym_mac_logs\"))\n",
    "    \n",
    "    query.awaitTermination()"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "454f57b3-1835-4760-8c8a-a1752774d035",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that we're using **trigger-available-now** logic for batch execution.  trigger-available-now is very similar to **trigger-once** but can run\n",
    "multiple batches until all available data is consumed instead of one big batch, and is introduced in <a href=\"https://spark.apache.org/releases/spark-release-3-3-0.html\" target=\"_blank\">Spark 3.3.0</a> and <a href=\"https://docs.databricks.com/release-notes/runtime/10.4.html\" target=\"_blank\">Databricks Runtime 10.4 LTS</a>. While we may not have the latency requirements of a Structured Streaming workload, Auto Loader prevents any CDC on our file source, allowing us to simply trigger a cron job daily to process all new data that's arrived."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "5deb481f-979b-4ceb-9a53-5b686ca6b1b3",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "load_gym_logs()"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "00ff3f1e-9100-44cf-9458-c6843ef04fa9",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "As always, each batch of newly processed data will create a new version of our table."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "8be8eb52-931c-4f1f-8ce2-d2a2f16d9715",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%sql \n",
    "DESCRIBE HISTORY gym_mac_logs"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "eee877ab-1da6-45a5-b78c-0cafb148cf9c",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "The helper method below will load an additional day of data."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "c224517a-7140-4ba8-b8de-dfcfe77dd6e8",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "DA.gym_mac_stream.load()"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "a87f8a9d-3586-47e8-8f6b-eac8c7bbf271",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "CloudFiles will ignore previously processed data; only those newly written files will be processed."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "e0beb3bf-b981-4295-bc6d-566a3e0423a4",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "load_gym_logs()"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "5f5478f0-4bcf-41ce-bc05-ebef038fba9d",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "source": [
    "%sql DESCRIBE HISTORY gym_mac_logs"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "115136fc-9056-4f8b-943d-2995a9de6d2d",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run the cell below to process the remainder of the data provided."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "7cc6d273-fbfd-461a-917e-8970b2f6c062",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "DA.gym_mac_stream.load(continuous=True)\n",
    "load_gym_logs()"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "fcf96319-2d27-4e0d-b324-eb52ed22d727",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "source": [
    "%sql DESCRIBE HISTORY gym_mac_logs"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "bc9e796f-c5b8-4938-96b6-04133a8f45b2",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can use SQL to examine our data."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "14568e50-17d1-43f7-84b2-c1b9ed47abe4",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%sql\n",
    "SELECT * FROM gym_mac_logs"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "13882877-ede8-4029-b93d-042fe4b99926",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run the following cell to delete the tables and files associated with this lesson."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "e5d4b1a3-aa53-49cb-8c6f-61c40c433c16",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "DA.cleanup()"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "842f4972-7e95-4fcf-aa89-8fee807889bc",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "notebookName": "ADE 99.5 - Auto Loader",
   "dashboards": [],
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "language": "python",
   "widgets": {},
   "notebookOrigID": 4185566132530301
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}