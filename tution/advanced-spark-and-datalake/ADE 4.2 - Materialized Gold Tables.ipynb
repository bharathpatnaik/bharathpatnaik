{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Materialized Gold Tables\n",
    "\n",
    "Because the lakehouse combines on-demand compute resources with infinitely scalable cloud object storage to optimize cost and performance, the concept of a materialized view most closely maps to that of a gold table. Rather than caching the results to the view for quick access, results are stored in Delta Lake for efficient deserialization.\n",
    "\n",
    "**NOTE**: Databricks SQL leverages <a href=\"https://docs.databricks.com/sql/admin/query-caching.html#query-caching\" target=\"_blank\">Delta caching and query caching</a>, so subsequent execution of queries will use cached results.\n",
    "\n",
    "Gold tables refer to highly refined, generally aggregate views of the data persisted to Delta Lake.\n",
    "\n",
    "These tables are intended to drive core business logic, dashboards, and applications.\n",
    "\n",
    "The necessity of gold tables will evolve over time; as more analysts and data scientists use your Lakehouse, analyzing query history will reveal trends in how data is queried, when, and by whom. Collaborating across teams, data engineers and platform admins can define SLAs to make highly valuable data available to teams in a timely fashion, all while cutting down the potential costs and latency associated with larger ad hoc queries.\n",
    "\n",
    "In this notebook, we'll create a gold table that stores summary statistics about each completed workout alongside binned demographic information. In this way, our application can quickly populate statistics about how other users performed on the same workouts.\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/ade/ADE_arch_bpm_summary.png\" width=\"60%\" />\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this lesson, students will be able to:\n",
    "- Describe performance differences between views and tables\n",
    "- Implement a streaming aggregate table"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "62e9021c-c758-4d2a-a94a-915c2856e27e",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "Set up path and checkpoint variables (these will be used later)."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "463597d4-7a4b-4fce-af52-7a60e71cddba",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%run ../Includes/Classroom-Setup-5.2"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "c9d61f70-f94f-4148-9c04-52a750778785",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Explore Workout BPM\n",
    "Recall that our **`workout_bpm`** table has already matched all completed workouts to user bpm recordings.\n",
    "\n",
    "Explore this data below."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "438fe401-9369-4e7b-ba99-10d5d7ee4979",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%sql\n",
    "SELECT * \n",
    "FROM workout_bpm\n",
    "LIMIT 10"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "1c31919d-290d-40c4-a535-49d2182d6ed8",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we calculate some summary statistics for our workouts."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "b47deb01-c921-4e28-9e12-eab85273e23a",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%sql\n",
    "SELECT user_id, workout_id, session_id, MIN(heartrate) min_bpm, MEAN(heartrate) avg_bpm, MAX(heartrate) max_bpm, COUNT(heartrate) num_recordings\n",
    "FROM workout_bpm\n",
    "GROUP BY user_id, workout_id, session_id"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "ca923cc9-b769-456f-a786-7a0cdf817cfa",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "And now we can use our **`user_lookup`** table to match this back to our binned demographic information."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "8dc5236b-7607-4eb0-857c-3c29ba0991d5",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%sql\n",
    "SELECT workout_id, session_id, a.user_id, age, gender, city, state, min_bpm, avg_bpm, max_bpm, num_recordings\n",
    "FROM user_bins a\n",
    "INNER JOIN \n",
    "  (SELECT user_id, workout_id, session_id, \n",
    "          min(heartrate) AS min_bpm, \n",
    "          mean(heartrate) AS avg_bpm,\n",
    "          max(heartrate) AS max_bpm, \n",
    "          count(heartrate) AS num_recordings\n",
    "   FROM workout_bpm\n",
    "   GROUP BY user_id, workout_id, session_id) b\n",
    "ON a.user_id = b.user_id"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "020c4b2b-9cc4-4062-826e-3012d1b0b6a9",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Perform an Incremental Batch Table Update\n",
    "Because our **`workout_bpm`** table was written as an append-only stream, we can update our aggregation using a streaming job as well."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "194ff0b5-3fc0-4251-b3ed-66afb9a4218f",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "(spark.readStream\n",
    "      .table(\"workout_bpm\")\n",
    "      .createOrReplaceTempView(\"TEMP_workout_bpm\"))"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "c6c672e4-28f5-46cd-8ff8-9c2a40f10f19",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using trigger-available-now logic with Delta Lake, we can ensure that we'll only calculate new results if records have changed in the upstream source tables."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "7caea8a3-c2f6-448f-ab48-66d0b5b5690c",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "user_bins_df = spark.sql(\"\"\"\n",
    "    SELECT workout_id, session_id, a.user_id, age, gender, city, state, min_bpm, avg_bpm, max_bpm, num_recordings\n",
    "    FROM user_bins a\n",
    "    INNER JOIN\n",
    "      (SELECT user_id, workout_id, session_id, \n",
    "              min(heartrate) AS min_bpm, \n",
    "              mean(heartrate) AS avg_bpm, \n",
    "              max(heartrate) AS max_bpm, \n",
    "              count(heartrate) AS num_recordings\n",
    "       FROM TEMP_workout_bpm\n",
    "       GROUP BY user_id, workout_id, session_id) b\n",
    "    ON a.user_id = b.user_id\n",
    "    \"\"\")\n",
    "\n",
    "(user_bins_df\n",
    "     .writeStream\n",
    "     .format(\"delta\")\n",
    "     .option(\"checkpointLocation\", f\"{DA.paths.checkpoints}/workout_bpm_summary\")\n",
    "     .option(\"path\", f\"{DA.paths.user_db}/workout_bpm_summary.delta\")\n",
    "     .outputMode(\"complete\")\n",
    "     .trigger(availableNow=True)\n",
    "     .table(\"workout_bpm_summary\")\n",
    "     .awaitTermination())"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "bd42f2d5-a7e5-4ef9-a9b4-5d49f6e18bb4",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Query Results\n",
    "\n",
    "Note that the primary benefit to scheduling updates to gold tables as opposed to defining views is the ability to control costs associated with materializing results.\n",
    "\n",
    "While returning results from this table will use some compute to scan the **`workout_bpm_summary`** table, this design avoids having to scan and join files from multiple tables every time this data is referenced."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "368c1f5c-3e1a-47b4-a7ee-660e0d2a3d3a",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%sql\n",
    "SELECT * FROM workout_bpm_summary"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "46f31292-51e8-4d5e-9bb0-42f726746edc",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run the following cell to delete the tables and files associated with this lesson."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "02a0ecb8-903e-43fd-821a-0777f519a793",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "DA.cleanup()"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "b8de0de6-ab1f-4272-83fe-d3966f3fe12e",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "notebookName": "ADE 4.2 - Materialized Gold Tables",
   "dashboards": [],
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "language": "python",
   "widgets": {},
   "notebookOrigID": 4185566132530379
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}