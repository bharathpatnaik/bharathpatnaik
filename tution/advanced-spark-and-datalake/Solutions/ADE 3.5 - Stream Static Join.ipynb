{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Stream-Static Joins\n",
    "\n",
    "In this lesson, you'll join streaming heart rate data with the completed workouts table.\n",
    "\n",
    "We'll be creating the table **`workout_bpm`** in our architectural diagram.\n",
    "\n",
    "This pattern will take advantage of Delta Lake's ability to guarantee that the latest version of a table is returned each time it is queried.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/ade/ADE_arch_workout_bpm.png\" width=\"60%\" />\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this lesson, students will be able to:\n",
    "- Describe guarantees around versioning and matching for stream-static joins\n",
    "- Leverage Spark SQL and PySpark to process stream-static joins"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "f03f045b-a874-491c-9201-2d40653be1bf",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "\n",
    "**NOTE**: The setup script includes logic to define a **`user_lookup`** table required for the join below."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "462d30de-09c6-4dab-b383-f55f0d44e83c",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%run ../Includes/Classroom-Setup-4.5"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "53d6d327-da03-4961-8156-4210d17f321e",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set up your streaming temp view. Note that we will only be streaming from **one** of our tables. The **`completed_workouts`** table is no longer streamable as it breaks the requirement of an ever-appending source for Structured Streaming. However, when performing a stream-static join with a Delta table, each batch will confirm that the newest version of the static Delta table is being used."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "58aa0c1d-638b-4fe5-a5bd-8c55a571d40f",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "(spark.readStream\n",
    "      .table(\"heart_rate_silver\")\n",
    "      .createOrReplaceTempView(\"TEMP_heart_rate_silver\"))"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "9ed4de9c-77a2-4ecf-b430-36f9a9733b7d",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Perform Stream-Static Join to Align Workouts to Heart Rate Recordings\n",
    "\n",
    "Below we'll configure our query to join our stream to our **`completed_workouts`** table.\n",
    "\n",
    "Note that our heart rate recordings only have **`device_id`**, while our workouts use **`user_id`** as the unique identifier. We'll need to use our **`user_lookup`** table to match these values. Because all tables are Delta Lake tables, we're guaranteed to get the latest version of each table during each microbatch transaction.\n",
    "\n",
    "Importantly, our devices occasionally send messages with negative recordings, which represent a potential error in the recorded values. We'll need to define predicate conditions to ensure that only positive recordings are processed."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "a79f836f-60c3-4200-ba90-2503f8dc8dea",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%sql \n",
    "CREATE OR REPLACE TEMP VIEW TEMP_workout_bpm AS\n",
    "  SELECT d.user_id, d.workout_id, d.session_id, time, heartrate\n",
    "  FROM TEMP_heart_rate_silver c\n",
    "  INNER JOIN (\n",
    "    SELECT a.user_id, b.device_id, workout_id, session_id, start_time, end_time\n",
    "    FROM completed_workouts a\n",
    "    INNER JOIN user_lookup b\n",
    "    ON a.user_id = b.user_id) d\n",
    "  ON c.device_id = d.device_id AND time BETWEEN start_time AND end_time\n",
    "  WHERE c.bpm_check = 'OK'"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "f34c818b-efe6-4d8e-afc4-f323ff5c4efa",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that the streaming portion of the join drives this join process. As currently implemented, this means that records from the **`heart_rate_silver`** table will only appear in our results table if a matching record has been written to the **`completed_workouts`** table prior to processing this query.\n",
    "\n",
    "Stream-static joins are not stateful, meaning that we cannot configure our query to wait for records to appear in the right side of the join prior to calculating the results. When leveraging stream-static joins, make sure to be aware of potential limitations for unmatched records. (Note that a separate batch job could be configured to find and insert records that were missed during incremental execution)."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "3ec0ea61-cd33-4c28-b296-cb8de77f41d0",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Write Stream in Append Mode\n",
    "\n",
    "Below, we'll use our streaming temp view from above to insert new values into our **`workout_bpm`** table."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "c59875fa-4505-4809-8d2d-ec5d29ddb10c",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def process_workout_bpm():\n",
    "    query = (spark.table(\"TEMP_workout_bpm\")\n",
    "                  .writeStream\n",
    "                  .format(\"delta\")\n",
    "                  .outputMode(\"append\")\n",
    "                  .option(\"checkpointLocation\", f\"{DA.paths.checkpoints}/workout_bpm\")\n",
    "                  .trigger(availableNow=True)\n",
    "                  .table(\"workout_bpm\"))\n",
    "    \n",
    "    query.awaitTermination()\n",
    "    \n",
    "process_workout_bpm()"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "2963f429-e82a-464f-b34e-08e127b5d0c1",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Explore this results table below."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "95aabdcc-f066-4c4e-b781-c6f603ffa30d",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%sql\n",
    "\n",
    "SELECT COUNT(*)\n",
    "FROM workout_bpm"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "e5bb97c9-80e6-420e-9197-94d57563f332",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "source": [
    "%sql\n",
    "\n",
    "SELECT * FROM workout_bpm"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "d9fe3af0-654b-434f-b885-40a8319f0c13",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "If desired, process another batch through all tables and update these results."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "1dfe5388-8a7f-4316-99d7-9748b7511d2a",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "DA.daily_stream.load()          # Load one new day for DA.paths.source_daily\n",
    "DA.process_bronze()             # Process through the bronze table\n",
    "DA.process_heart_rate_silver()  # Process the heart_rate_silver table\n",
    "DA.process_workouts_silver()    # Process the workouts_silver table\n",
    "DA.process_completed_workouts() # Process the completed_workouts table\n",
    "\n",
    "process_workout_bpm()"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "ae35793f-931b-46f5-913d-bafa1e004ee8",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "source": [
    "%sql\n",
    "\n",
    "SELECT COUNT(*)\n",
    "FROM workout_bpm"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "356c65d8-7e92-4c89-9c95-1e20c0eca6a7",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run the following cell to delete the tables and files associated with this lesson."
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "24234bb1-a7ee-4bfc-9373-b609ba665ff4",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "DA.cleanup()"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "87e3c824-2521-4d80-872c-da9fc3960b6d",
     "inputWidgets": {},
     "title": ""
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "notebookName": "ADE 3.5 - Stream Static Join",
   "dashboards": [],
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "language": "python",
   "widgets": {},
   "notebookOrigID": 4185566132529042
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}